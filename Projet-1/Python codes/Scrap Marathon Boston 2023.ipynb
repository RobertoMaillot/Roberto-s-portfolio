{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5d875dd-2957-42d0-bdf1-d81d88df8412",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06ab9868-559e-48be-85d3-4931f4057838",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = requests.get('https://results.baa.org/2023/?pid=list&pidp=start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2d2e838-047b-4404-925c-e67c17c272a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d56b7058-59ab-4d69-b562-01235e732eed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soup=bs(response.text,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a72c064c-8d72-4ddb-8821-8c2063d19bff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chebet, Evans',\n",
       " 'Obiri, Hellen',\n",
       " 'Ravichandran, Kae',\n",
       " 'Geay, Gabriel',\n",
       " 'Beriso, Amane',\n",
       " 'Calamia, Cal',\n",
       " 'Kipruto, Benson',\n",
       " 'Salpeter, Lonah',\n",
       " 'Powers, Matthew',\n",
       " 'Korir, Albert',\n",
       " 'Yeshaneh, Ababel',\n",
       " 'Parkin, Chris',\n",
       " 'Talbi, Zouhair',\n",
       " 'Bates, Emma',\n",
       " 'Dill, Nicholas',\n",
       " 'Kipchoge, Eliud',\n",
       " 'Weldu, Nazret',\n",
       " 'Johnson, Andre',\n",
       " 'Fauble, Scott',\n",
       " 'Tanui, Angela',\n",
       " 'Harris, Zackary',\n",
       " 'Chahdi, Hassan',\n",
       " 'Gebremaryam, Hiwot',\n",
       " 'Palmer, Miche',\n",
       " 'Korir, John']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_tags = soup.find_all('h4', {'class' : \"list-field type-fullname\"})\n",
    "name = []\n",
    "for tag in name_tags:\n",
    "    name.append(tag.text.strip())\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7aa4379d-a6db-4b7d-8577-725d1a870846",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '1',\n",
       " '36',\n",
       " '1',\n",
       " '568',\n",
       " '2',\n",
       " '2',\n",
       " '40',\n",
       " '2',\n",
       " '1938',\n",
       " '3',\n",
       " '3',\n",
       " '41',\n",
       " '3',\n",
       " '2674',\n",
       " '4',\n",
       " '4',\n",
       " '42',\n",
       " '4',\n",
       " '5191',\n",
       " '5',\n",
       " '5',\n",
       " '44',\n",
       " '5',\n",
       " '5230',\n",
       " '6',\n",
       " '6',\n",
       " '56',\n",
       " '6',\n",
       " '5809',\n",
       " '7',\n",
       " '7',\n",
       " '63',\n",
       " '7',\n",
       " '7676',\n",
       " '8',\n",
       " '8',\n",
       " '66',\n",
       " '8',\n",
       " '7717',\n",
       " '9',\n",
       " '9']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_tags = soup.find_all('div', {'class' : \"list-field type-place place-secondary hidden-xs numeric\"})\n",
    "rank = []\n",
    "for tag in rank_tags:\n",
    "    rank.append(tag.text.strip())\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "627276fe-60af-401c-a8c7-c2ddc1f8f5a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HALFHALF',\n",
       " 'Finish NetFinish Net',\n",
       " 'Finish GunFinish Gun',\n",
       " 'HALF01:11:54',\n",
       " 'Finish Net02:24:33',\n",
       " 'Finish Gun02:24:33',\n",
       " 'HALF01:30:33',\n",
       " 'Finish Net03:16:19',\n",
       " 'Finish Gun03:18:52',\n",
       " 'HALF01:03:59',\n",
       " 'Finish Net02:10:17',\n",
       " 'Finish Gun02:10:17',\n",
       " 'HALF01:11:30',\n",
       " 'Finish Net02:24:34',\n",
       " 'Finish Gun02:24:34',\n",
       " 'HALF01:24:06',\n",
       " 'Finish Net03:17:19',\n",
       " 'Finish Gun03:17:19',\n",
       " 'HALF01:02:20',\n",
       " 'Finish Net02:10:25',\n",
       " 'Finish Gun02:10:25',\n",
       " 'HALF01:11:54',\n",
       " 'Finish Net02:24:37',\n",
       " 'Finish Gun02:24:37',\n",
       " 'HALF01:35:57',\n",
       " 'Finish Net03:17:25',\n",
       " 'Finish Gun03:20:06',\n",
       " 'HALF01:02:20',\n",
       " 'Finish Net02:10:33',\n",
       " 'Finish Gun02:10:33',\n",
       " 'HALF01:11:30',\n",
       " 'Finish Net02:24:44',\n",
       " 'Finish Gun02:24:44',\n",
       " 'HALF01:39:00',\n",
       " 'Finish Net03:18:47',\n",
       " 'Finish Gun03:18:59',\n",
       " 'HALF01:03:59',\n",
       " 'Finish Net02:10:52',\n",
       " 'Finish Gun02:10:52',\n",
       " 'HALF01:11:54',\n",
       " 'Finish Net02:24:49',\n",
       " 'Finish Gun02:24:49',\n",
       " 'HALF01:37:05',\n",
       " 'Finish Net03:19:14',\n",
       " 'Finish Gun03:23:03',\n",
       " 'HALF01:04:36',\n",
       " 'Finish Net02:11:26',\n",
       " 'Finish Gun02:11:26',\n",
       " 'HALF01:12:22',\n",
       " 'Finish Net02:24:51',\n",
       " 'Finish Gun02:24:51',\n",
       " 'HALF01:39:57',\n",
       " 'Finish Net03:22:33',\n",
       " 'Finish Gun03:27:32',\n",
       " 'HALF01:02:20',\n",
       " 'Finish Net02:11:50',\n",
       " 'Finish Gun02:11:50',\n",
       " 'HALF01:11:55',\n",
       " 'Finish Net02:24:58',\n",
       " 'Finish Gun02:24:58',\n",
       " 'HALF01:38:10',\n",
       " 'Finish Net03:23:39',\n",
       " 'Finish Gun03:27:32',\n",
       " 'HALF01:04:00',\n",
       " 'Finish Net02:12:22',\n",
       " 'Finish Gun02:12:22',\n",
       " 'HALF01:11:29',\n",
       " 'Finish Net02:25:07',\n",
       " 'Finish Gun02:25:07',\n",
       " 'HALF01:40:20',\n",
       " 'Finish Net03:23:45',\n",
       " 'Finish Gun03:30:00',\n",
       " 'HALF01:05:40',\n",
       " 'Finish Net02:13:27',\n",
       " 'Finish Gun02:13:27',\n",
       " 'HALF01:12:17',\n",
       " 'Finish Net02:25:48',\n",
       " 'Finish Gun02:25:48']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_tags = soup.find_all('div', {'class' : \"split list-field type-time\"})\n",
    "time = []\n",
    "for tag in time_tags:\n",
    "    time.append(tag.text.strip())\n",
    "\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6659d1ed-b612-472f-a945-ba7f5617bffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "\n",
    "# all products info\n",
    "products = []\n",
    "\n",
    "# iterate over items\n",
    "for item in items:\n",
    "\n",
    "    # to be completed\n",
    "    item_description=item.find(\"a\", {\"class\": \"product-item-link\"})\n",
    "    \n",
    "    item_name= item_description.text.strip()\n",
    "    item_url= item_description.attrs[\"href\"]\n",
    "    item_price=float(item.find(\"span\",{\"class\":\"price\"}).text.strip().replace(\"\\xa0€\",\"\").replace(\",\",\".\"))\n",
    "    \n",
    "    # product info\n",
    "    product_info = {\n",
    "        \"product_name\": item_name,\n",
    "        \"price\": item_price,\n",
    "        \"url\": item_url\n",
    "    }\n",
    "\n",
    "    # append product_info to products\n",
    "    products.append(product_info)\n",
    "\n",
    "df = pd.DataFrame(products)\n",
    "df\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "881e689c-5ba0-47ca-b2da-6c184e141166",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 19 (3405080905.py, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[38], line 20\u001b[0;36m\u001b[0m\n\u001b[0;31m    name.append(tag.text.strip())\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 19\n"
     ]
    }
   ],
   "source": [
    "# i = 1 jusqu'à 1065\n",
    "    \n",
    "#all athletes info\n",
    "    \n",
    "athletes={'name':[],\n",
    "         'time':[]}\n",
    "name = []\n",
    "time = []\n",
    "\n",
    "for i in range(1,2):\n",
    "        \n",
    "    url = f'https://results.baa.org/2023/?page={i}&pid=list&pidp=start'\n",
    "    \n",
    "    response=requests.get(url)\n",
    "    soup=BeautifulSoup(response.text,\"html.parser\")\n",
    "        \n",
    "    name_tags = soup.find_all('h4', {'class' : \"list-field type-fullname\"})\n",
    "    for tag in name_tags:\n",
    "    name.append(tag.text.strip())\n",
    "\n",
    "    \n",
    "    time_tags = soup.find_all('div', {'class' : \"split list-field type-time\"})\n",
    "    for tag in time_tags:\n",
    "    time.append(tag.text.strip())\n",
    "\n",
    "        \n",
    "    # athlete info\n",
    "    athletes = {\n",
    "        \"name\": name,\n",
    "        \"time\": time,\n",
    "    }\n",
    "    \n",
    "# combine all products in a single DataFrame\n",
    "df = pd.DataFrame(athletes)\n",
    "    \n",
    "df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c444dee4-6b26-424a-bb2a-ca1c5506d2fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m         athletes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(tag\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip())\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# create DataFrame\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(athletes)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# display the DataFrame\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:709\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    703\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    704\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    705\u001b[0m     )\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 709\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/construction.py:481\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    479\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/construction.py:115\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m         index \u001b[38;5;241m=\u001b[39m _extract_index(arrays)\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/construction.py:655\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    653\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    659\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    660\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# all athletes info\n",
    "athletes = {'name': [], 'time': []}\n",
    "\n",
    "for i in range(1, 2):  # Loop from 1 to 1065\n",
    "    url = f'https://results.baa.org/2023/?page={i}&pid=list&pidp=start'\n",
    "\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # athlete names\n",
    "    name_tags = soup.find_all('h4', {'class': \"list-field type-fullname\"})\n",
    "    for tag in name_tags:\n",
    "        athletes['name'].append(tag.text.strip())\n",
    "\n",
    "    # athlete times\n",
    "    time_tags = soup.find_all('div', {'class': \"split list-field type-time\"})\n",
    "    for tag in time_tags:\n",
    "        athletes['time'].append(tag.text.strip())\n",
    "\n",
    "# create DataFrame\n",
    "df = pd.DataFrame(athletes)\n",
    "\n",
    "# display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7903c7-d4e1-4e84-8fba-ee4afdea9d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
